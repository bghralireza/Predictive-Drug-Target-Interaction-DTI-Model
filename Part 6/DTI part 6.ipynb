{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96771b61-7e7a-4c22-859a-77fdc164f4fc",
   "metadata": {},
   "source": [
    "# Phase 6: Web Application Deployment Workflow\n",
    "\n",
    "The deployment workflow requires separating your Python code into a backend (where the heavy ma-chine learning happens) and a frontend (the user interface).\n",
    "\n",
    "### 1. Backend: Model Serving and API Creation\n",
    "\n",
    "The backend is responsible for receiving the user's input (a new SMILES string and a new protein se-quence) and running the prediction pipeline.\n",
    "\n",
    "- ##### Step 6.1: Serializing the Model (Saving)\n",
    "\n",
    "Save your final trained PyTorch model (the check-point weights) and any necessary pre-processing objects (like the atom/bond feature maps, or protein sequence embedding dictionary) using a serialization format like PyTorch's state dic-tionary (.pt) or Python's pickle.\n",
    "\n",
    "- ##### Step 6.2: Create the Inference Pipeline\n",
    "Write a single, robust Python function that:\n",
    "   - Accepts raw inputs (SMILES, Sequence).\n",
    "   - Performs the exact same Feature Engineering steps (SMILES to Graph, Sequence to 1D-CNN input).\n",
    "   - Loads the saved model weights.\n",
    "   - Runs the prediction (forward pass).\n",
    "   - Returns the final prediction (binding probability or affinity score).\n",
    "\n",
    "- ##### Step 6.3: Build a REST API\n",
    "\n",
    "Use a fast, lightweight Python framework like FastAPI or Flask to wrap your inference function as a web service endpoint (an API).\n",
    "\n",
    "-    Example: A user sends a POST request to your-app.com/predict with the SMILES and Sequence in the JSON body, and the API responds with the DTI score.\n",
    "\n",
    "### 2. Frontend: User Interface and Interaction\n",
    "The frontend is the visual component that users interact with. For ML/Bioinformatics projects, rapid prototyping frameworks are highly effective.\n",
    "\n",
    "- ##### Step 6.4: Choose a Rapid Prototyping Framework:\n",
    "- Streamlit (Recommended): This is the most popular and easiest option for Python-based ML deployment. It allows you to build a sophisticated web interface (text inputs, file uploads, sliders) using only Python code.\n",
    "- Gradio: Another excellent choice for fast prototyping, often used to wrap models quickly.\n",
    "- Plotly Dash: Good for more complex interactive dashboards and visualizations if needed.\n",
    "\n",
    "- ##### Step 6.5: Design the User Interface:\n",
    "- Provide two clear input boxes: one for the SMILES string and one for the Protein Se-quence (or UniProt ID).\n",
    "- Add a \"Predict\" button.\n",
    "- Display the prediction result clearly (e.g., \"Predicted Binding Probability: 0.92\").\n",
    "\n",
    "- ##### Step 6.6: Implement Visualization (Value Add): Integrate the interpretability steps from Phase 5 by displaying:\n",
    "- The 2D chemical structure of the input SMILES (using RDKit/Streamlit components).\n",
    "- The attention or saliency map overlaid on the protein sequence, highlighting the predicted binding residues.\n",
    "\n",
    "### 3. Final Deployment and Hosting\n",
    "\n",
    "To make your application publicly available, you need a hosting service.\n",
    "\n",
    "- ##### Step 6.7: Environment Setup:\n",
    "\n",
    "Create a requirements.txt or environment.yml file listing all dependencies (PyTorch, PyG, RDKit, Streamlit, etc.) and their exact versions. This ensures your app runs correctly everywhere.\n",
    "\n",
    "- ##### Step 6.8: Version Control and Hosting\n",
    "\n",
    "Upload your entire project (API code, inference script, saved model, and environment file) to GitHub.\n",
    "\n",
    "- ##### Step 6.9: Cloud Deployment\n",
    "Choose a free/low-cost cloud platform that supports Python web apps:\n",
    "- Streamlit Cloud: Offers a streamlined, free deployment option specifically for Stream-lit apps, linking directly to your GitHub repository.\n",
    "- Hugging Face Spaces: Excellent for hosting ML demos.\n",
    "- Heroku, Google Cloud Run, or AWS: More complex but offer greater control and scalability for production-level apps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa80f12c-6216-4ce4-9769-7c08298f2662",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
