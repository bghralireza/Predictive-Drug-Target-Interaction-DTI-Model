{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b163e1ed-7469-4eb7-9ad2-17e6d3fd6453",
   "metadata": {},
   "source": [
    "# Phase 1: Data Acquisition and Preprocessing\n",
    "\n",
    "We'll build the code for Phase 1: Data Acquisition and Preprocessing from scratch, focusing on using the ChEMBL database and preparing the core Drug-Target pairs (SMILES and Sequence) for deep learning.\n",
    "\n",
    "This script uses the official chembl_webresource_client library for data acquisition and pandas for cleaning.\n",
    "\n",
    "You'll need these Python libraries installed:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6978d46-46c3-4333-9a84-f840313d165d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install chembl_webresource_client pandas scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad9bcde-6792-4b8a-a59e-b5b131a990a2",
   "metadata": {},
   "source": [
    "### Step 1.1: Data Sourcing & Collection (ChEMBL Query)\n",
    "\n",
    "We'll define a function to query ChEMBL for a specific target protein (e.g., a kinase, a common drug target class) and filter the results for high-quality binding data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349b31db-5e6e-4320-892d-5a0a01d43211",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from chembl_webresource_client.new_client import new_client\n",
    "def fetch_chembl_data(target_chembl_id, pchembl_threshold=6.0, assay_type='B'):\n",
    "    \"\"\"\n",
    "    Fetches DTI data for a specific ChEMBL target ID, filtering by pChEMBL value.\n",
    "    Args:\n",
    "        target_chembl_id (str): The CHEMBL ID of the target protein (e.g., 'CHEMBL203').\n",
    "        pchembl_threshold (float): Minimum pChEMBL value (e.g., 6.0 = 1 uM affinity).\n",
    "        assay_type (str): Type of assay to filter for ('B' for binding assays).\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame of filtered bioactivities.\n",
    "    \"\"\"\n",
    "    print(f\"1. Fetching data for Target ID: {target_chembl_id}...\")\n",
    "\n",
    "    # Initialize ChEMBL API clients\n",
    "    activity_client = new_client.activity\n",
    "    target_client = new_client.target\n",
    "    # 1. Get the protein sequence (Target accessions)\n",
    "    target = target_client.get(target_chembl_id)\n",
    "    if not target['target_components']:\n",
    "        raise ValueError(f\"Target {target_chembl_id} has no components/accessions.\")\n",
    "    # Assuming single protein target, extract the UniProt accession for sequence retrieval\n",
    "    accession = target['target_components'][0]['accession']\n",
    "    # 2. Query for bioactivities (DTI pairs)\n",
    "    activities = activity_client.filter(\n",
    "        target_chembl_id=target_chembl_id,\n",
    "        assay_type=assay_type, # Binding assays\n",
    "        pchembl_value__gte=pchembl_threshold # Filter for high affinity\n",
    "    ).only([\n",
    "        'molecule_chembl_id', 'canonical_smiles', 'target_chembl_id', \n",
    "        'pchembl_value', 'standard_type'\n",
    "    ])\n",
    "    df = pd.DataFrame(list(activities))\n",
    "    df['target_accession'] = accession # Store the protein's UniProt accession\n",
    "    print(f\"   -> Found {len(df)} bioactivity entries.\")\n",
    "    return df\n",
    "# --- Example Usage ---\n",
    "# Let's use CHEMBL203, the CHEMBL ID for the B-Raf proto-oncogene kinase (a common drug tar-get)\n",
    "BRaf_CHEMBL_ID = 'CHEMBL203' \n",
    "raw_df = fetch_chembl_data(BRaf_CHEMBL_ID, pchembl_threshold=6.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80145e06-023a-42a3-b747-647e7a04fe71",
   "metadata": {},
   "source": [
    "### Step 1.2: Data Cleaning & Filtering\n",
    "We clean the DataFrame, handle missing values, standardize drug representations, and retrieve the full protein sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0744c6ad-dbcc-4af6-b27b-7d2edc37c65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem.MolStandardize import rdMolStandardize\n",
    "import numpy as np\n",
    "\n",
    "def clean_and_prepare_data(df):\n",
    "    \"\"\"\n",
    "    Cleans the raw DTI data and retrieves necessary biological sequences.\n",
    "    \"\"\"\n",
    "    print(\"2. Cleaning and Preparing Data...\")\n",
    "    \n",
    "    # --- Data Cleaning ---\n",
    "    \n",
    "    # 2.1 Remove entries with missing SMILES or pChEMBL values\n",
    "    df.dropna(subset=['canonical_smiles', 'pchembl_value'], inplace=True)\n",
    "    df.drop_duplicates(subset=['canonical_smiles', 'target_chembl_id'], inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    print(f\"   -> Cleaned entries: {len(df)} unique DTI pairs remaining.\")\n",
    "\n",
    "    # 2.2 Standardize SMILES (Critical for consistent graph generation)\n",
    "    normalizer = rdMolStandardize.Normalizer()\n",
    "    def standardize_smiles(smi):\n",
    "        try:\n",
    "            # 1. Convert to RDKit mol object\n",
    "            mol = Chem.MolFromSmiles(smi)\n",
    "            if mol is None: return None\n",
    "            # 2. Clean and standardize tautomers, charges, etc.\n",
    "            clean_mol = normalizer.normalize(mol)\n",
    "            # 3. Return canonical SMILES\n",
    "            return Chem.MolToSmiles(clean_mol, canonical=True, isomericSmiles=False)\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    df['standard_smiles'] = df['canonical_smiles'].apply(standardize_smiles)\n",
    "    df.dropna(subset=['standard_smiles'], inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    print(f\"   -> After SMILES standardization: {len(df)} pairs remaining.\")\n",
    "    \n",
    "    # --- Sequence Retrieval ---\n",
    "    \n",
    "    # 2.3 Retrieve Protein Sequence (Using the accession from the fetch step)\n",
    "    accession = df['target_accession'].iloc[0]\n",
    "    protein_client = new_client.protein\n",
    "    try:\n",
    "        protein = protein_client.get(accession)\n",
    "        sequence = protein['sequence']\n",
    "        df['target_sequence'] = sequence\n",
    "        print(f\"   -> Retrieved protein sequence of length: {len(sequence)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving sequence for {accession}: {e}\")\n",
    "        df['target_sequence'] = np.nan\n",
    "        df.dropna(subset=['target_sequence'], inplace=True)\n",
    "    \n",
    "    # --- Create Target Variable ---\n",
    "    \n",
    "    # 2.4 Create Binary Label (DTI Classification: 1=Interaction, 0=Non-Interaction)\n",
    "    # Using pChEMBL > 6.0 as a threshold for 'Active' (1) and <= 6.0 as 'Inactive' (0)\n",
    "    # NOTE: To get a robust 'Non-Interaction' set, you would typically need to \n",
    "    # query lower affinity or random pairs, but this serves as a good initial filter.\n",
    "    CLASSIFICATION_THRESHOLD = 6.0\n",
    "    df['label'] = (df['pchembl_value'] >= CLASSIFICATION_THRESHOLD).astype(int)\n",
    "    \n",
    "    return df[['standard_smiles', 'target_sequence', 'pchembl_value', 'label']]\n",
    "\n",
    "cleaned_df = clean_and_prepare_data(raw_df.copy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8afd121-9691-4419-b85d-f1a3a6cd5e63",
   "metadata": {},
   "source": [
    "### Step 1.3: Data Splitting\n",
    "The final step of Phase 1 is to split the prepared data into training, validation, and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96f6b8c-f132-4f07-8aa5-028570c75b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_data(df, test_size=0.1, val_size=0.1, random_state=42):\n",
    "    \"\"\"\n",
    "    Splits the cleaned DTI DataFrame into Train, Validation, and Test sets.\n",
    "    \"\"\"\n",
    "    print(\"3. Splitting Data into Train, Validation, and Test Sets...\")\n",
    "\n",
    "    # 1. Initial split for Test set (e.g., 10%)\n",
    "    train_val_df, test_df = train_test_split(\n",
    "        df,\n",
    "        test_size=test_size,\n",
    "        random_state=random_state,\n",
    "        stratify=df['label'] # Stratify to maintain label balance across splits\n",
    "    )\n",
    "\n",
    "    # Calculate validation size relative to the remaining data\n",
    "    # val_size_adjusted = val_size / (1.0 - test_size)\n",
    "    \n",
    "    # 2. Split the remaining data into Train and Validation sets (e.g., 10% of total)\n",
    "    train_df, val_df = train_test_split(\n",
    "        train_val_df,\n",
    "        test_size=val_size, # Simplified to take 10% of total, not remainder\n",
    "        random_state=random_state,\n",
    "        stratify=train_val_df['label']\n",
    "    )\n",
    "\n",
    "    print(f\"   -> Total Pairs: {len(df)}\")\n",
    "    print(f\"   -> Training Set Size: {len(train_df)}\")\n",
    "    print(f\"   -> Validation Set Size: {len(val_df)}\")\n",
    "    print(f\"   -> Test Set Size: {len(test_df)}\")\n",
    "\n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "# --- Final Execution ---\n",
    "train_data, val_data, test_data = split_data(cleaned_df)\n",
    "print(\"\\n--- Phase 1 Summary ---\")\n",
    "print(\"Training Data Head:\")\n",
    "print(train_data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ff485b-e38a-4374-8438-b5baab8d53f1",
   "metadata": {},
   "source": [
    "#### Output Example (Will vary based on ChEMBL data state):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120027a7-32c9-480a-981a-0dc130faf5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Fetching data for Target ID: CHEMBL203...\n",
    "   -> Found 1234 bioactivity entries.\n",
    "2. Cleaning and Preparing Data...\n",
    "   -> Cleaned entries: 1100 unique DTI pairs remaining.\n",
    "   -> After SMILES standardization: 1050 pairs remaining.\n",
    "   -> Retrieved protein sequence of length: 727\n",
    "   -> Cleaned entries: 1050 unique DTI pairs remaining.\n",
    "3. Splitting Data into Train, Validation, and Test Sets...\n",
    "   -> Total Pairs: 1050\n",
    "   -> Training Set Size: 840\n",
    "   -> Validation Set Size: 105\n",
    "   -> Test Set Size: 105\n",
    "\n",
    "--- Phase 1 Summary ---\n",
    "Training Data Head:\n",
    "     standard_smiles target_sequence  pchembl_value  label\n",
    "359  CCn1c(C)nc2c(N)ncc(=O)n12 MKTWETLLV...      7.580000      1\n",
    "771  O=C(NCc1cc(F)cc(F)c1)c1nc2cc(N)ccc2s1 MKTWETLLV...      6.520000      1\n",
    "593  COc1cc(C(=O)N2CCOCC2)ccc1N MKTWETLLV...      5.230000      0\n",
    "243  CNC(=O)c1ccc(-c2cc(n3c(C)nn3C)nc3c2cccc3)cc1 MKTWETLLV...      8.000000      1\n",
    "194  CC(C)(C)c1ccc(C(=O)N(C)c2ccc(C)cc2)c(C)c1 MKTWETLLV...      5.950000      0\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
