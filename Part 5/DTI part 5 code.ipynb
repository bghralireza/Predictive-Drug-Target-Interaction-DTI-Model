{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68df031c-6f17-43e1-aa2a-aef6a8c35b84",
   "metadata": {},
   "source": [
    "# Phase 5: Evaluation and Interpretation\n",
    "\n",
    "This is the final, crucial step! Phase 5: Evaluation and Interpretation involves two main goals: rigorously measuring the model's performance on the unseen Test Set and extracting biological insights (interpretability).\n",
    "\n",
    "Here is the code implementation from scratch, integrating the evaluation metrics and a basic interpretability method (analysis of embedding space).\n",
    "\n",
    "##### Prerequisites\n",
    "We'll assume you have the necessary classes and data splits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150a2ec6-47e0-47c5-a08d-b94739f1dbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, confusion_matrix\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import List\n",
    "\n",
    "# --- ASSUMED IMPORTS/SETUP FROM PREVIOUS PHASES ---\n",
    "# from my_model_scripts import DTIModel, custom_collate, DTIDataset \n",
    "# from my_data_scripts import test_data # The DataFrame for the held-out test set\n",
    "\n",
    "# Define constants from previous phases\n",
    "DRUG_IN_FEAT = 71\n",
    "TARGET_IN_FEAT = 21\n",
    "EMBEDDING_DIM = 128\n",
    "HIDDEN_DIM = 64\n",
    "GNN_LAYERS = 3\n",
    "CNN_KERNEL_SIZE = 8\n",
    "MAX_LEN = 1200\n",
    "BATCH_SIZE = 32\n",
    "CHECKPOINT_PATH = 'dti_model_best.pt' # Path where Phase 4 saved the best weights\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03214fe5-f8f6-4556-a0c1-d80f6de80493",
   "metadata": {},
   "source": [
    "### 1. Model Evaluation on the Test Set (Proving Performance)\n",
    "This function runs the final trained model on the test data and calculates the key binary classification metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79ebbf1-4912-432a-a018-a58b3235cb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_on_test_set(test_df: pd.DataFrame, checkpoint_path: str):\n",
    "    \"\"\"\n",
    "    Loads the best model, performs prediction on the test set, and calculates metrics.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (metrics_dict, all_labels, all_predictions, model)\n",
    "    \"\"\"\n",
    "    print(\"1. Loading best model and setting up Test Evaluation...\")\n",
    "    \n",
    "    # 1. Initialize and Load Model\n",
    "    model = DTIModel(\n",
    "        drug_in_feat=DRUG_IN_FEAT, target_in_feat=TARGET_IN_FEAT, hidden_dim=HIDDEN_DIM,\n",
    "        gnn_layers=GNN_LAYERS, cnn_kernel_size=CNN_KERNEL_SIZE, embedding_dim=EMBEDDING_DIM\n",
    "    ).to(DEVICE)\n",
    "    \n",
    "    # Check if checkpoint exists and load weights\n",
    "    if not os.path.exists(checkpoint_path):\n",
    "        print(f\"Error: Checkpoint file not found at {checkpoint_path}. Using uninitialized model.\")\n",
    "    else:\n",
    "        model.load_state_dict(torch.load(checkpoint_path, map_location=DEVICE))\n",
    "    \n",
    "    model.eval() # Set model to evaluation mode\n",
    "    \n",
    "    # 2. Setup DataLoader\n",
    "    test_dataset = DTIDataset(test_df, max_len=MAX_LEN) \n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=custom_collate)\n",
    "\n",
    "    all_labels, all_probabilities = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for drug_batch, target_batch, labels in test_loader:\n",
    "            drug_batch = drug_batch.to(DEVICE)\n",
    "            target_batch = target_batch.to(DEVICE)\n",
    "            \n",
    "            # Predict probabilities\n",
    "            predictions = model(drug_batch, target_batch).cpu().numpy().flatten()\n",
    "            \n",
    "            all_probabilities.extend(predictions)\n",
    "            all_labels.extend(labels.cpu().numpy().flatten())\n",
    "\n",
    "    # 3. Calculate Metrics\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_probabilities = np.array(all_probabilities)\n",
    "    \n",
    "    # Calculate AUROC and AUPRC\n",
    "    auroc = roc_auc_score(all_labels, all_probabilities)\n",
    "    auprc = average_precision_score(all_labels, all_probabilities)\n",
    "    \n",
    "    # Convert probabilities to binary predictions using a threshold (e.g., 0.5)\n",
    "    threshold = 0.5\n",
    "    binary_predictions = (all_probabilities >= threshold).astype(int)\n",
    "    \n",
    "    # Calculate Confusion Matrix and derived metrics\n",
    "    tn, fp, fn, tp = confusion_matrix(all_labels, binary_predictions).ravel()\n",
    "    accuracy = (tp + tn) / len(all_labels)\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    \n",
    "    metrics = {\n",
    "        'Test AUROC': auroc,\n",
    "        'Test AUPRC': auprc,\n",
    "        'Test Accuracy': accuracy,\n",
    "        'Test Precision': precision,\n",
    "        'Test Recall': recall,\n",
    "        'TN': tn, 'FP': fp, 'FN': fn, 'TP': tp\n",
    "    }\n",
    "    \n",
    "    print(\"\\n--- Final Test Metrics ---\")\n",
    "    print(pd.Series(metrics).drop(['TN', 'FP', 'FN', 'TP']))\n",
    "    \n",
    "    return metrics, all_labels, all_probabilities, model\n",
    "\n",
    "# --- DUMMY EXECUTION (Needs real test_data and checkpoint) ---\n",
    "# test_metrics, test_labels, test_probabilities, final_model = evaluate_on_test_set(test_data, CHECKPOINT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd96092-4b8e-4cfb-87d6-2eb72d3097b2",
   "metadata": {},
   "source": [
    "### 2. Global Interpretation (Embedding Visualization)\n",
    "This function uses t-SNE to reduce the high-dimensional drug and protein feature vectors ($\\mathbf{V}_D$ and $\\mathbf{V}_P$) down to 2D for visualization, checking if the model clusters similar compounds/targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbedbf4a-fb82-4496-8927-9b4788ae8af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_embeddings(model: nn.Module, test_loader: DataLoader):\n",
    "    \"\"\"\n",
    "    Extracts drug and target embeddings from the test set and visualizes them using t-SNE.\n",
    "    \"\"\"\n",
    "    print(\"\\n2. Extracting Embeddings for t-SNE Visualization...\")\n",
    "    model.eval()\n",
    "    all_v_d, all_v_p, all_labels = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for drug_batch, target_batch, labels in test_loader:\n",
    "            drug_batch = drug_batch.to(DEVICE)\n",
    "            target_batch = target_batch.to(DEVICE)\n",
    "            \n",
    "            # Extract V_D and V_P before concatenation/fusion\n",
    "            v_d = model.drug_encoder(drug_batch).cpu().numpy()\n",
    "            v_p = model.target_encoder(target_batch).cpu().numpy()\n",
    "            \n",
    "            all_v_d.append(v_d)\n",
    "            all_v_p.append(v_p)\n",
    "            all_labels.extend(labels.cpu().numpy().flatten())\n",
    "\n",
    "    V_D_matrix = np.vstack(all_v_d)\n",
    "    V_P_matrix = np.vstack(all_v_p)\n",
    "    labels = np.array(all_labels)\n",
    "    \n",
    "    # --- Perform t-SNE on both embeddings ---\n",
    "    tsne_v_d = TSNE(n_components=2, random_state=42, perplexity=30).fit_transform(V_D_matrix)\n",
    "    tsne_v_p = TSNE(n_components=2, random_state=42, perplexity=30).fit_transform(V_P_matrix)\n",
    "    \n",
    "    # --- Visualization ---\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    \n",
    "    # 2.1 Drug Embeddings Plot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.scatterplot(x=tsne_v_d[:, 0], y=tsne_v_d[:, 1], hue=labels, palette='viridis', legend='full', alpha=0.7)\n",
    "    plt.title('t-SNE of Drug Embeddings ($\\mathbf{V}_D$)', fontsize=14)\n",
    "    plt.xlabel('t-SNE Component 1')\n",
    "    plt.ylabel('t-SNE Component 2')\n",
    "    plt.legend(title='Binding Label')\n",
    "    \n",
    "    # 2.2 Target Embeddings Plot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.scatterplot(x=tsne_v_p[:, 0], y=tsne_v_p[:, 1], hue=labels, palette='viridis', legend='full', alpha=0.7)\n",
    "    plt.title('t-SNE of Target Embeddings ($\\mathbf{V}_P$)', fontsize=14)\n",
    "    plt.xlabel('t-SNE Component 1')\n",
    "    plt.ylabel('t-SNE Component 2')\n",
    "    plt.legend(title='Binding Label')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# --- FINAL EXECUTION (REQUIRES DUMMY DATA/MODEL TO BE REPLACED) ---\n",
    "# test_dataset = DTIDataset(test_data, max_len=MAX_LEN) \n",
    "# test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=custom_collate)\n",
    "# visualize_embeddings(final_model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8848bdc4-af7e-4068-9cb9-e19485b33ea8",
   "metadata": {},
   "source": [
    "### 3. Local Interpretation (Attention/Saliency - Conceptual)\n",
    "For this basic implementation, explicit attention mechanisms were not built into the Phase 3 model. However, here is the conceptual workflow for interpretation, which is vital for the biological context:\n",
    "- Goal: Determine which atoms (Drug) and which amino acids (Target) are most important for the positive prediction of binding.\n",
    "- Technique (Post-hoc): Use Gradient-based Saliency Maps.\n",
    "    - Take a single True Positive DTI pair.\n",
    "    - Calculate the gradient of the final prediction score with respect to the input features (the $\\mathbf{X}$ node features for the drug and the OHE matrix for the protein).\n",
    "    - The magnitude of this gradient at each feature position (atom or residue) indicates its importance to the prediction.\n",
    "    - Visualize: Map the high-magnitude gradients back onto the 2D molecule structure (RDKit) and the 1D protein sequence to highlight the predicted pharmacophore and binding pocket residues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4fbe76-1ba1-43ef-b7a4-357e24c932fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
