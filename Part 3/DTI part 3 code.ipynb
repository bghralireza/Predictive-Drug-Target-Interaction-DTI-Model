{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3e991a7-b5b7-4eec-aba2-45c6292c5c65",
   "metadata": {},
   "source": [
    "# Phase 3: Model Architecture Design and Implementation (The Model Core)\n",
    "\n",
    "Building the architecture involves defining three components: the Drug Encoder (GNN), the Target Encoder (CNN), and the Prediction Head (Fusion & FNN).\n",
    "\n",
    "Since you have two heterogeneous inputs (a Graph from the drug and a Tensor from the protein), we must also define a custom collate_fn for the DataLoader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611ffcad-61b6-4535-bf77-368f15326f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_max_pool\n",
    "from torch_geometric.data import Batch\n",
    "from torch.utils.data import DataLoader\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf09838-2030-4b6a-b8e3-e8db63543512",
   "metadata": {},
   "source": [
    "### 1. Drug Encoder (Graph Neural Network - GNN)\n",
    "We'll use a simple Graph Convolutional Network (GCN) followed by a global pooling operation to gen-erate a fixed-size drug feature vector (VD)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19675cc-9e73-4b70-b333-522d9934d3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DrugGNN(nn.Module):\n",
    "    def __init__(self, in_features, hidden_dim, gnn_layers, embedding_dim):\n",
    "        super(DrugGNN, self).__init__()\n",
    "        # Initial linear layer to project input features to hidden_dim\n",
    "        self.initial_lin = nn.Linear(in_features, hidden_dim)\n",
    "        \n",
    "        # Stack multiple GCN layers\n",
    "        self.convs = nn.ModuleList([\n",
    "            GCNConv(hidden_dim, hidden_dim) for _ in range(gnn_layers)\n",
    "        ])\n",
    "        \n",
    "        # Final linear layer to project pooled features to the final embedding dimension\n",
    "        self.final_lin = nn.Linear(hidden_dim, embedding_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        \n",
    "        # 1. Initial Feature Projection\n",
    "        x = self.initial_lin(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # 2. GNN Layers\n",
    "        for conv in self.convs:\n",
    "            x = conv(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            x = self.dropout(x)\n",
    "        \n",
    "        # 3. Global Pooling (Graph Classification Layer)\n",
    "        # global_max_pool aggregates node features (x) across all nodes in each graph (batch)\n",
    "        x = global_max_pool(x, batch)\n",
    "        \n",
    "        # 4. Final Embedding\n",
    "        v_d = self.final_lin(x)\n",
    "        return v_d # V_D: Drug Feature Vector (Shape: Batch_size x embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2b8565-53b6-4a2e-9c5b-529586aeefab",
   "metadata": {},
   "source": [
    "### 2. Target Encoder (1D Convolutional Neural Network - CNN)\n",
    "This module processes the padded, one-hot encoded amino acid sequence matrix to generate the protein feature vector (VP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6e9545-8a17-4dba-968b-d791777d0a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TargetCNN(nn.Module):\n",
    "    def __init__(self, in_features, hidden_channels, kernel_size, embedding_dim):\n",
    "        super(TargetCNN, self).__init__()\n",
    "        \n",
    "        # The input tensor is (Batch_size, Sequence_Length, in_features=21)\n",
    "        # CNN expects (Batch_size, Channels, Length), so we need to transpose:\n",
    "        \n",
    "        # 1. 1D Convolutional Layers\n",
    "        self.conv1 = nn.Conv1d(in_channels=in_features, out_channels=hidden_channels, ker-nel_size=kernel_size, padding=kernel_size//2)\n",
    "        self.conv2 = nn.Conv1d(hidden_channels, hidden_channels * 2, kernel_size=kernel_size, pad-ding=kernel_size//2)\n",
    "        self.conv3 = nn.Conv1d(hidden_channels * 2, hidden_channels * 4, kernel_size=kernel_size, padding=kernel_size//2)\n",
    "        \n",
    "        # 2. Final Pooling Layer\n",
    "        # We use Global Max Pooling to get a fixed-size vector regardless of sequence length\n",
    "        self.global_pool = nn.AdaptiveMaxPool1d(1)\n",
    "        \n",
    "        # 3. Final Linear Layer to project pooled features to the final embedding dimension\n",
    "        self.final_lin = nn.Linear(hidden_channels * 4, embedding_dim)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, sequence_tensor):\n",
    "        # Transpose the input for Conv1D: (B, L, F) -> (B, F, L)\n",
    "        x = sequence_tensor.permute(0, 2, 1)\n",
    "        \n",
    "        # 1. Convolution Blocks\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # 2. Global Pooling: (B, F_out, L) -> (B, F_out, 1)\n",
    "        x = self.global_pool(x).squeeze(-1)\n",
    "        \n",
    "        # 3. Final Embedding\n",
    "        v_p = self.final_lin(x)\n",
    "        return v_p # V_P: Protein Feature Vector (Shape: Batch_size x embedding_dim)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e240e2bf-a8b4-4866-abc1-c8ef840623ef",
   "metadata": {},
   "source": [
    "### 3. Combined DTI Prediction Model (Fusion Head)\n",
    "This class combines the two encoders and uses a simple Concatenation Fusion followed by a Feed-Forward Network (FNN) for the final prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8f52f5-4ae9-44f3-90a6-d68f3615fd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DTIModel(nn.Module):\n",
    "    def __init__(self, drug_in_feat, target_in_feat, hidden_dim, gnn_layers, cnn_kernel_size, embed-ding_dim, fc_layers=2):\n",
    "        super(DTIModel, self).__init__()\n",
    "        \n",
    "        # Encoders\n",
    "        self.drug_encoder = DrugGNN(drug_in_feat, hidden_dim, gnn_layers, embedding_dim)\n",
    "        self.target_encoder = TargetCNN(target_in_feat, hidden_dim, cnn_kernel_size, embedding_dim)\n",
    "        \n",
    "        # Fusion Head (Predictor)\n",
    "        # Input size is 2 * embedding_dim due to concatenation (V_D + V_P)\n",
    "        self.fc_input_size = embedding_dim * 2\n",
    "        \n",
    "        self.fnn = nn.Sequential(\n",
    "            nn.Linear(self.fc_input_size, self.fc_input_size // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(self.fc_input_size // 2, 1) # Final output is a single score\n",
    "        )\n",
    "\n",
    "    def forward(self, drug_data, target_tensor):\n",
    "        # 1. Encode Drug and Target\n",
    "        v_d = self.drug_encoder(drug_data)\n",
    "        v_p = self.target_encoder(target_tensor)\n",
    "        \n",
    "        # 2. Feature Fusion: Concatenation\n",
    "        v_pair = torch.cat([v_d, v_p], dim=1) # Shape: (Batch_size, 2 * embedding_dim)\n",
    "        \n",
    "        # 3. Prediction Head\n",
    "        # Use sigmoid for classification (probability output)\n",
    "        score = torch.sigmoid(self.fnn(v_pair))\n",
    "        \n",
    "        return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f180b122-508f-4de6-8bfe-19f6f991a124",
   "metadata": {},
   "source": [
    "### 4. Custom Collate Function (The Glue)\n",
    "The DataLoader needs a custom function to batch the PyG Data objects (graphs) and the regular PyTorch Tensor (sequences) simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6f6563-5418-4e49-a300-cbfdf894a43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate(batch: List[Tuple[Data, torch.Tensor]]) -> Tuple[Batch, torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Custom collate function to create a batch for DTI data.\n",
    "    \n",
    "    Args:\n",
    "        batch: A list of tuples: [(drug_graph_1, target_tensor_1), (drug_graph_2, target_tensor_2), ...]\n",
    "        \n",
    "    Returns:\n",
    "        Tuple: (Batched Drug Data, Batched Target Tensor, Batched Labels)\n",
    "    \"\"\"\n",
    "    # 1. Separate the components\n",
    "    drug_graphs, target_tensors = zip(*batch)\n",
    "    \n",
    "    # 2. Batch Drug Graphs using PyG's built-in Batch class\n",
    "    # This correctly stacks node/edge features and creates the necessary 'batch' vector\n",
    "    drug_batch = Batch.from_data_list(drug_graphs)\n",
    "    \n",
    "    # 3. Batch Target Sequences using torch.stack\n",
    "    # Since all target tensors were already padded to max_len in Phase 2, this is straightforward\n",
    "    target_batch = torch.stack(target_tensors, dim=0) # Shape: (B, L, F)\n",
    "    \n",
    "    # 4. Extract Labels (y is stored in drug_graphs.y)\n",
    "    labels = torch.cat([g.y for g in drug_graphs], dim=0) # Shape: (B, 1)\n",
    "\n",
    "    return drug_batch, target_batch, labels\n",
    "\n",
    "# Note: You would initialize your DataLoader like this:\n",
    "# from torch.utils.data import DataLoader\n",
    "# dti_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=custom_collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdd502e-8c93-4880-b76c-c0b9463b5efa",
   "metadata": {},
   "source": [
    "This completes the architecture setup, providing all the necessary classes to initialize, train, and test your heterogeneous DTI model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143b04c9-d1f4-43f5-a1b3-022f5a75ad6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
